# Spark Streaming Application
![image](https://github.com/AysCeren/spark_app/assets/154695340/3c5d3c9d-6a88-461a-bb3a-9b682e0ee4d7)

## What is Spark?
Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.
Apache Spark is a data processing framework that can quickly perform processing tasks on very large data sets, and can also distribute data processing tasks across multiple computers, either on its own or in tandem with other distributed computing tools.

## What is Data Streaming?
Data streaming is the continuous transfer of data from one or more sources at a steady, high speed for processing into specific outputs. Combination of kafka and spark creates real-data streaming application.
Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window.
 **This project aims to consume data produced and written into Kafka topics, then transform, process, and analyze it to produce structured data ready for database storage.**
>You can see Kafka Producer Application: 
This general processed is called 
