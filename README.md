# Spark Streaming Application
![image](https://github.com/AysCeren/spark_app/assets/154695340/3c5d3c9d-6a88-461a-bb3a-9b682e0ee4d7)

## What is Spark?
Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters. It is a data processing framework that can quickly perform processing tasks on very large data sets, and can also distribute data processing tasks across multiple computers, either on its own or in tandem with other distributed computing tools.

## What is Data Streaming?
Data streaming is the continuous transfer of data from one or more sources at a steady, high speed for processing into specific outputs. Combination of kafka and spark creates real-data streaming application.

## What is Stream Processing?
Stream processing is a core concept of “Big Data” processing/analysis and event-driven architecture. In it simplest form, stream processing is reading an incoming stream of data, or sequence of events, in real time and performing some actions on that data producing an output.

![image](https://github.com/user-attachments/assets/e9f382da-e0ed-4437-89f6-d656bb15f771)

## What does our project aim?

Integrating Kafka and Spark can help you build a reliable and scalable data processing pipeline that can handle real-time data streams and turn them actionable Complex Event Processes (CEPs). Therefore, this project enables kafka and spark integration to make stream processing.

### Prerequisites:
+ Kafka Producer (You can check kafka_producer app: )

